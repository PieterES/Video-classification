# Video-classification
Video classification with a 2D + 1D convolutional neural network 
https://www.tensorflow.org/tutorials/video/video_classification

# load_data.py 

Demonstrates how to load and preprocess AVI video data using the UCF101 human action dataset. Once the data has been processed, it can be used for such tasks as video classification/recognition, captioning or clustering. The original dataset contains realistic action videos collected from YouTube with 101 categories, including playing cello, brushing teeth, and applying eye makeup. 

# video_class.py 

Demonstrates training a 3D convolutional neural network (CNN) for video classification using the UCF101 action recognition dataset. A 3D CNN uses a three-dimensional filter to perform convolutions. The kernel is able to slide in three directions, whereas in a 2D CNN it can slide in two dimensions. The model is based on the work published in A Closer Look at Spatiotemporal Convolutions for Action Recognition by D. Tran et al. (2017).

# Model Visualization
![alt text](https://github.com/PieterES/Video-classification/blob/main/model_visualization.png?raw=true)
